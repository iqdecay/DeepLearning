{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session 3: Multiple Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of this lab session: use a multiple layer perceptron to process MNIST dataset.\n",
    "\n",
    "\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits. It also includes labels for each image, telling us which digit it is. In this lab session, we're going to train a model to look at images and predict what digits they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start here with these lines of code which will download and read in the data automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into two parts: 60,000 data points of training data, 10,000 points of test data. It's essential in machine learning that we have separate data which we don't learn from so that we can make sure that what we've learned actually generalizes!\n",
    "\n",
    "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. \"x\" corresponds to images and \"y\" to labels. Both the training set and test set contain images and their corresponding labels.\n",
    "\n",
    "First, we will visualize some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff25499acf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  plt.axis('off')\n",
    "  index = np.where(y_train == i)[0][0]\n",
    "  plt.imshow(x_train[index,:,:], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "  plt.title('Training: %i' % y_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 28 pixels by 28 pixels. In this lab session, we flatten this array into a vector of 28x28 = 784 numbers.\n",
    "\n",
    "#### 1) Write the code to flatten the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 784))\n",
    "x_test = x_test.reshape((10000,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Write the code to normalize pixel intensity between 0 and 1 of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_max = np.amax(x_train)\n",
    "x_test_max = np.amax(x_test)\n",
    "x_test = np.array(np.true_divide(x_test, x_test_max))\n",
    "x_train = np.array(np.true_divide(x_train, x_train_max))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in MNIST has a corresponding label, a number between 0 and 9 representing the digit drawn in the image.\n",
    "\n",
    "In this lab session, we're going to want our labels as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the $n^{th}$ digit will be represented as a vector which is 1 in the $n^{th}$ dimension. For example, 3 would be $[0,0,0,1,0,0,0,0,0,0]$. \n",
    "\n",
    "#### 3) Convert the labels to one-hot vectors (using the function \"to_categorical\" available in Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "z_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "z_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression\n",
    "\n",
    "Every image in MNIST is of a handwritten digit between zero and nine. So there are only ten possible things that a given image can be. For a given image, we want to compute the probabilities for it being each digit. In this part, we will use a softmax regression model:\n",
    "\n",
    "$$ y = softmax(Wx+b)$$\n",
    "\n",
    "where $softmax$ is the normalized exponential function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)  Define a Keras network architecture for softmax regression using Sequential API (https://keras.io/models/sequential/). Use a Dense layer to define the softmax regression (https://keras.io/layers/core/#dense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# y = softmax (Wx+b)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10,input_shape=(784,), activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) How many trainable parameters are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to define the loss function. We try to minimize that error, and the smaller the error margin, the better our model is. In this lab session, \"cross-entropy\" is used as the loss of the model. It's defined as:\n",
    "\n",
    "$$H_{y}(z) = - \\sum_i y_i \\log(z_i)$$\n",
    "\n",
    "where $z$ is our predicted probability distribution, and $y$ is the true distribution (the one-hot vector with the digit labels). \n",
    "\n",
    "Now we need to specify the optimization algorithm that will be used to minimized the loss function. Here, we will use RMSprop. We will also specify a metric (here 'accuracy') to follow the convergence of the training step.\n",
    "\n",
    "#### 6) Specify in the Keras model the loss function, the optimization algorithm and the metric (see https://keras.io/models/sequential/#compile):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(RMSprop(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Write the code to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7818d932afbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;31m# `class_weight` arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             sample_weights = standardize_sample_weights(\n\u001b[0;32m--> 794\u001b[0;31m                 sample_weight, feed_output_names)\n\u001b[0m\u001b[1;32m    795\u001b[0m             class_weights = standardize_class_weights(\n\u001b[1;32m    796\u001b[0m                 class_weight, feed_output_names)\n",
      "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_sample_weights\u001b[0;34m(sample_weight, output_names)\u001b[0m\n\u001b[1;32m    198\u001b[0m     return standardize_sample_or_class_weights(sample_weight,\n\u001b[1;32m    199\u001b[0m                                                \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                                'sample_weight')\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_sample_or_class_weights\u001b[0;34m(x_weight, output_names, weight_type)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIn\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprovided\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \"\"\"\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "model.train_on_batch(x_train, z_train, batch_size, epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the convergence of the training step, we will plot the evolution of the accuracy for both training and testing data with respect to the epochs. The code to do this is provided below.\n",
    "\n",
    "#### 8) Study the convergence figure and the evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "#Visualize history (loss vs epochs)\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')  \n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, z_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that good? Compare your results with the score of the current best models: https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Write code to visualize the incorrect predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Study the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "class_names= ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple layer network\n",
    "\n",
    "#### 9) Build a multiple layer dense network to reach 98% of accuracy (at least!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
