{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELU 502 Deep learning -- Lab session 4\n",
    "Pierre-Henri Conze, Fran√ßois Rousseau - session : 1h20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of this lab session: perform classification on MNIST dataset using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lab session 3, MNIST classification has been performed relying on multi-layer perceptron (MLP). The obtained accuracy was 92% with a simple softmax regressor and 98% with MLP which can be further improved! Let us jump from this simple model to something moderately more sophisticated, namely convolutional neural networks.\n",
    "\n",
    "For recall, MNIST is a computer vision dataset which consists of handwritten digit images with associated label. Each image in MNIST has a corresponding label, a number between 0 and 9 representing the digit drawn in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data management and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us download and read the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) x_test shape: (10000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(28, 28) image size\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_test[0,:,:].shape, 'image size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into two parts: 60000 data points of training data, 10000 points of test data. Each image is 28 pixels by 28 pixels. \n",
    "Let us visualize some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb556931b38>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.axis('off')\n",
    "    index = np.where(y_train == i)[0][0]\n",
    "    plt.imshow(x_train[index,:,:],cmap=plt.cm.gray_r)\n",
    "    plt.title('Training: %i' % y_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further processing using keras functions, MNIST data must stacked in a 4D tensor with shape (samples, rows, cols, channels). In our case, channels=1 since we are working with greyscale images. As in lab session 3, pixel intensities need to rescaled between 0 and 1. Moreovre, labels can be described as one-hot vectors using the to_categorical() keras function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "# build 4D tensors\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "# data normalization\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "# convert class vectors to binary class matrices\n",
    "z_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "z_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Building a convolutional neural network with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequential Keras model is a linear stack of layers. You can create a sequential model by passing a list of layer instances to the constructor. Among the layer instances, you can use:\n",
    "  - convolutional layer using Conv2D (https://keras.io/layers/convolutional/#conv2d)\n",
    "  - max-pooling layer using MaxPooling2D (https://keras.io/layers/pooling/#maxpooling2d)\n",
    "  - Dropout (https://keras.io/layers/core/#dropout)\n",
    "  - regular densely-connected layer using Dense (https://keras.io/layers/core/#dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once keras modules have been imported, we can simply add layers using the .add() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_ = (img_rows, img_cols, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Create a convolutional neural network following the architecture given below:\n",
    " - convolutional layer using 32 3x3 filters with stride 1 and \"ReLU\" activation\n",
    " - convolutional layer using 64 3x3 filters with stride 1 and \"ReLU\" activation\n",
    " - max pooling with vertical, horizontal downscale of 2\n",
    " - flatten layer (https://keras.io/layers/core/#flatten) to flatten the input array\n",
    " - dense layer with 128 units\n",
    " - dense layer with \"num_classes=10\" units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=input_shape_, filters= 32, kernel_size=(3,3), strides=(1,1),activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),strides=(1,1),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "a =     len(np.where(y_train == 10))\n",
    "\n",
    "model.add(Dense(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, you need to configure the learning process, which is done through the compile() method. It receives three arguments:\n",
    "\n",
    " - an optimizer: this could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class.\n",
    " - A loss function: this is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or an objective function.\n",
    " - A list of metrics to evaluate results. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Define the loss, the optimizer and the metrics. Then, compile your model. You can find some help from https://keras.io/models/sequential/#compile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(...) # to do\n",
    "from keras.optimizers import Adam\n",
    "model.compile(\"adam\", \"mean_squared_error\",metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Describe input/output sizes of each layer. Confirm your analysis by using model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,198,721\n",
      "Trainable params: 1,198,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Input                                               Output\n",
    "28*28, greyscale (0 to 1)                         26*26, same\n",
    "26*26, same                                       24*24, same\n",
    "24*24, same                                       12*12, same  \n",
    "12*12, same                                        144, same\n",
    "\n",
    "\"\"\"\n",
    "model.summary()\n",
    "\n",
    "#model.fit(x_train, y_train, 128, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Keras models are trained on Numpy arrays of input data and labels. For training a model, we can use the fit() function (https://keras.io/models/sequential/#fit). Run the training using a batch size of 128 and 12 epochs. Test data will be used as validatation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "# to do\n",
    "history = model.fit(x_train, y_train, 128, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.fit() method returns an History callback, which has a history attribute containing the lists of successive losses and other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Display the loss and the accuracy across training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Evaluate the global test loss and accuracy using the evaluate() method (https://keras.io/models/sequential/#evaluate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Visualize some wrongly predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we have learned how to quickly and easily build, train, and evaluate a convolutional neural network using Keras. The final test set accuracy on MNIST dataset is approximately 99% which is better than the results obtained with MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Robustness to noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Evaluate the network predictions on noisy data with two different noise factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.axis('off')\n",
    "    index = np.where(y_test == i)[0][0]\n",
    "    plt.imshow(x_test_noisy[index,:,:,0], cmap=plt.cm.gray_r)\n",
    "    plt.title('%i' % y_test[index])\n",
    "plt.show()\n",
    "score = model.evaluate(x_test_noisy, z_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.4\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.axis('off')\n",
    "    index = np.where(y_test == i)[0][0]\n",
    "    plt.imshow(x_test_noisy[index,:,:,0], cmap=plt.cm.gray_r)\n",
    "    plt.title('%i' % y_test[index])\n",
    "plt.show()\n",
    "score = model.evaluate(x_test_noisy, z_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With strong noise, the accuracy decreases from 99% to 80% since training samples are not enough representative. Let us train the model directly on noisy data samples to see the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Train and evaluate the same CNN architecture on noisy data with 0.4 as noise factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_noisy = ...\n",
    "# model_noise = Sequential()\n",
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) What is the expected result when using Dropout layers? Evaluate the network without Dropout layers and conclude based on global test accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_noise2 = Sequential()\n",
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this small convolutional network, performance is actually nearly identical with and without dropout. Here, when training and predict on noisy data, we jump from 97,8% (without dropout) to 98,0% (with dropout). Dropout is often very effective at reducing overfitting, but it is most useful when training very large neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Towards more deeper networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last part, we come back to the original dataset, i.e. without additional noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) Implement a deeper convolutional neural network by adding two convolutional  layers and one max pooling layer before the first Dropout. What is the performance gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slightly more deeper network reaches around 99,35% in terms of accuracy (instead of 99% as in question 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12) Study the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "z_pred = model2.predict(x_test)\n",
    "y_pred = np.argmax(z_pred,axis=1)\n",
    "\n",
    "class_names= ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To conclude, an overview of results obtained with different methodologies can be found here: https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
